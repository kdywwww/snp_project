{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238ad20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a810ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/app/bucket/data/raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ba23220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_feature(df, target, n_lags, freq, extend_rows=False, drop_target=True):\n",
    "    \"\"\"\n",
    "    DataFrame의 특정 열(들)에 대해 지정된 기간만큼 Lag 변수를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 시계열 인덱스(DatetimeIndex)를 가진 원본 데이터프레임.\n",
    "        target (str): Lag 변수를 생성할 열 이름.\n",
    "        n_lags (int): 지연시킬 기간 (정수 시점 또는 시간 문자열).\n",
    "            - int: 시계열 인덱스의 '행' 개수만큼 지연 (예: 1일, 7일).\n",
    "        freq (str): df의 인덱스(datetime)의 빈도 문자열 (예: 'D', 'M', 'MS').\n",
    "        extend_rows (bool, optional): True이면 데이터프레임의 마지막 날짜 이후로 n_lags 기간만큼의 새로운 인덱스를 추가합니다. 기본값은 False입니다.\n",
    "        drop_target (bool, optional): True이면 원본 target 열을 삭제합니다. 기본값은 True입니다.\n",
    "    \n",
    "    Returns:\n",
    "        new_df (pd.DataFrame): Lag 변수가 추가된 새로운 데이터프레임.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df = new_df.sort_index()\n",
    "    index_name = new_df.index.name if new_df.index.name else 'ds'\n",
    "\n",
    "    if extend_rows:\n",
    "        # 마지막 날짜 이후로 n_lags 기간만큼의 새로운 인덱스 생성\n",
    "        start = new_df.index[-1] + pd.tseries.frequencies.to_offset(freq)\n",
    "        future_dates = pd.date_range(start=start, periods=n_lags, freq=freq)\n",
    "        new_df = pd.concat([new_df, pd.DataFrame(index=future_dates)], axis=0)\n",
    "        new_df.index.name = index_name\n",
    "        \n",
    "    # Lag 변수명 생성 (예: 'Close_lag_1' 또는 'VIX_lag_2M')\n",
    "    lag_name = f\"{target}_lag_{n_lags}{freq}\"\n",
    "    # shift() 함수를 사용하여 Lag 변수 생성\n",
    "    new_df[lag_name] = new_df[target].shift(periods=n_lags, freq=None)\n",
    "\n",
    "    if drop_target:\n",
    "        # 원본 target 열 삭제\n",
    "        new_df.drop(columns=[target], inplace=True)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ab60c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MS_to_D_ffill(df):\n",
    "    \"\"\"\n",
    "    월초(freq='MS') DatetimeIndex를 가진 DataFrame을 \n",
    "    일별(Daily) 빈도로 확장하고, NaN 값을 ffill로 채웁니다.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 월별 DatetimeIndex를 가진 DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        new_df (pd.DataFrame): 일별 빈도로 확장되고 ffill 처리된 DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = df.copy()\n",
    "    new_df = new_df.sort_index()\n",
    "    \n",
    "    # 1. 일별 DatetimeIndex 생성\n",
    "    daily_index = pd.date_range(\n",
    "        start=new_df.index.min(),\n",
    "        end=new_df.index.max() + pd.tseries.frequencies.to_offset(\"MS\"),\n",
    "        freq='D' # 일별 빈도(Daily Frequency) 지정\n",
    "    )\n",
    "    \n",
    "    # 2. Reindex (일별 인덱스로 확장)\n",
    "    index_name = new_df.index.name if new_df.index.name else 'ds'\n",
    "    new_df = new_df.reindex(daily_index)\n",
    "    new_df.index.name = index_name\n",
    "    \n",
    "    # 3. ffill (Forward Fill)\n",
    "    new_df = new_df.fillna(method='ffill')\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPY 데이터 읽기 및 전처리\n",
    "spy_df = pd.read_csv(os.path.join(data_dir, 'spy_data.csv'))\n",
    "spy_df = spy_df[['datetime', 'close', 'volume']]\n",
    "spy_df.rename(columns={'close': 'spy_close', 'volume': 'spy_volume'}, inplace=True)\n",
    "spy_df['ds'] = pd.to_datetime(spy_df['datetime'], format='%Y-%m-%d')\n",
    "spy_df.set_index('ds', inplace=True)\n",
    "spy_df.drop(columns=['datetime'], inplace=True)\n",
    "spy_df = spy_df.sort_index()\n",
    "spy_df = create_lag_feature(df=spy_df, target='spy_volume', n_lags=1, freq=\"D\", extend_rows=False, drop_target=True)\n",
    "spy_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_df = pd.read_csv(os.path.join(data_dir, 'cli_data.csv'))\n",
    "cli_df = cli_df[['datetime', 'CLI']]\n",
    "cli_df['ds'] = pd.to_datetime(cli_df['datetime'], format='%Y-%m-%d')\n",
    "cli_df.set_index('ds', inplace=True)\n",
    "cli_df.drop(columns=['datetime'], inplace=True)\n",
    "cli_df = cli_df.sort_index()\n",
    "cli_df = create_lag_feature(df=cli_df, target='CLI', n_lags=1, freq=\"MS\", extend_rows=True, drop_target=True)\n",
    "cli_df = MS_to_D_ffill(cli_df)\n",
    "cli_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.merge(spy_df,\n",
    "                     cli_df,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how=\"left\")\n",
    "total_df = total_df.fillna(method=\"ffill\")\n",
    "total_df = total_df.dropna(how=\"any\")\n",
    "print(total_df.shape)\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc9527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
